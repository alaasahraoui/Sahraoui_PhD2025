\chapter{Introduction}\label{chap:Introduction}


\section{Context and Motivations}\label{sec:Introduction}

\paragraph{Software and contextual evolution.}
\textit{Software evolution}~\cite{Lehman:1980} is the continuous process of developing, maintaining, and updating software after its initial release to meet changing requirements and needs. Software evolution is required when (non-)functional requirements change, when the \textit{context of use} evolves, or when usability errors, bugs, and security vulnerabilities need to be fixed~\cite{Mens:2008:book,Zaidman:2010}. The \textit{context of use} \cite{Calvary:2003,Dey:2001} of an interactive application encompasses the end user and the related interactive tasks, the computing platform, and the environment in which interaction takes place. Consequently, any \textit{contextual evolution} of one of these three dimensions, such as the arrival of a new category of users~\cite{Pleuss:2013}, an updated task~\cite{Vandenbergh:2010}, a new version of the operating system, a new form factor for the UI, or an evolving physical and social environment~\cite{Mens:2008:intro}, is relevant to software evolution. In the presence of contextual evolution, the User Interface (UI) itself should change accordingly, thus raising challenges of \textit{contextual adaptation}~\cite{Calvary:2025}, a particular case of software evolution in which the UI needs to be adapted to the evolving context of use~\cite{Abrahao:2021}.

\paragraph{The promise of adaptive and context-aware UIs.}
``The goal is not to replace people but to empower them by making design choices that give humans control over technology,'' as stated by Shneiderman \cite{Shneiderman:2022}. This sentiment encapsulates a core challenge in modern Human–Computer Interaction (HCI): as UIs become increasingly adapted to new contexts, how can we ensure that the \textit{user} remains in control of this adaptation?

Ambient intelligent environments, such as smart homes, intelligent meeting rooms, or context-aware workspaces, automatically tailor UIs to situational factors (user preferences, devices at hand, physical environment) in order to enhance usability. This vision of ubiquitous computing promises UIs that seamlessly ``mold'' to their context of use, \ie exhibit \textit{plasticity}~\cite{Calvary:2007}. Adaptive User Interfaces (AUIs) incorporate \textit{adaptivity}: the ability of the system to autonomously adjust UI content, layout, or behavior in response to contextual changes~\cite{Browne:1990}. Typical examples include a smartphone application switching to a dark theme at night, or a car dashboard simplifying its display when the driver’s cognitive load is high. These adaptive capabilities are associated with several \textbf{anticipated advantages}~\cite{Gajos:2008,Gajos:2010}:

\begin{itemize}
  \item \textbf{Improved efficiency:} the system pre-configures the UI for the current context of use, reducing the number of manual steps required from the user.
  \item \textbf{Reduced cognitive load:} by hiding non-relevant functions and emphasizing relevant ones, the UI can become easier to scan and operate.
  \item \textbf{Better fit to the context of use:} adaptation enables the same application to function across a variety of devices, environments, and user profiles, supporting UI plasticity.
  \item \textbf{Personalization:} over time, adaptive mechanisms can tailor interaction styles and content to user preferences or habits.
\end{itemize}

However, these benefits often come with important \textit{drawbacks}~\cite{Lavie:2010} when adaptation remains opaque to the user~\cite{Eloi:2024}:
\begin{itemize}
  \item \textbf{Loss of control:} the system may make changes that the user does not understand or did not request, creating a feeling of being ``acted upon'' rather than in charge.
  \item \textbf{Lack of predictability:} if users cannot anticipate when and how the UI will adapt, they may struggle to form stable mental models of the interface.
  \item \textbf{Opacity and ``black-box'' behavior:} adaptation logic frequently operates behind the scenes; users cannot see which rules or models are responsible for changes, nor inspect alternative options.
  \item \textbf{Mismatches and errors:} when system assumptions about relevance are wrong (\eg due to noisy context sensing or biased models), critical information can be hidden or distorted without the user noticing.
  \item \textbf{Erosion of trust:} repeated unexpected changes and unexplained system decisions can reduce user confidence in the system’s reliability and fairness \cite{Bellotti:2001}.
\end{itemize}

Traditional UIs are largely static~\cite{Vanderdonckt:2020}: they require manual reconfiguration if the context changes, placing the burden on users to adapt themselves to the interface. AUIs remove part of this burden but introduce a new problem: because adaptation logic is automated and often invisible, users frequently have no clear way to observe or influence it. The UI might change suddenly without explanation and users are expected to simply accept these changes. In low-stakes scenarios this may remain a mild annoyance (``Why did the font size change on its own?''), but in high-stakes contexts the lack of control can be detrimental.

\paragraph{Motivating scenarios.}
Consider a crime investigation dashboard that uses machine learning to automatically highlights certain suspects. If the system’s AUI misjudges relevance and filters out a crucial piece of evidence, the investigating officer might not realize what has been omitted, nor have any direct means to correct or override the system’s decision. Likewise, imagine an ambient smart room where mid-air gestures are used to control IoT devices: a system that remaps a command to another gesture without informing the user, could result to frustration or even unsafe situations.

These scenarios highlight a critical gap in today’s adaptive systems: \textbf{users lack agency and insight into the adaptation process when it matters most}. Users need ways to see what the UI is doing (\textit{observability}) and to shape, configure or veto adaptation decisions (\textit{controllability}) when automatic adaptations do not align with their intentions. Recent HCI work has underscored the importance of keeping humans ``in the loop'' of adaptation decisions to maintain transparency and trust \cite{Dessart:2011}. Without explicit support for user control, adaptive interfaces risk becoming opaque ``black boxes'' that undermine their own usability advantages. This doctoral research is motivated by the imperative to reconcile the benefits of adaptivity with the principle of user empowerment.

\paragraph{Meta-User Interfaces: interfaces about interfaces.}
One approach to addressing this problem emerged in the early 2000s with the concept of the \textit{meta-user interface} (meta-UI). A meta-UI was originally defined as ``the set of functions (and their associated user interfaces) that are necessary and sufficient to \textit{monitor and control} the state of an interactive ambient space'' \cite{Coutaz:2006,Demeure:2011}. In simpler terms, a meta-UI is an interface \textit{about} the interface: an auxiliary UI that allows users to observe what an ambient system is doing and to intervene in its configuration or behavior.

This concept was introduced to cope with the complexity of context-awareness by making the ambient system’s state and possible adaptations visible and manipulable to its users. For example, a meta-UI presents a control dashboard for managing distributed displays in a smart room, or a visualization of active modalities in a multimodal system that users can toggle on/off \cite{Vanderhulst:2009}. Early research demonstrated meta-UIs for tasks such as controlling UI \textit{plasticity} on mobile devices, managing multi-user collaborative settings, or orchestrating multi-surface interactions. By providing a ``UI for the UI'', these solutions sought to restore a degree of user agency and transparency in environments that would otherwise adapt automatically and invisibly.

Meta-UIs have thus been \textit{reasonably well explored} in the literature and have attracted a significant number of design proposals and case studies. However, as we will argue, many of these implementations actually correspond to a more specific class of interfaces that later came to be called \textit{Extra-User Interfaces}.

\paragraph{From Meta-UI to Extra-UI and Mega-UI.}
Over time, the meta-UI idea has been refined and extended. Extra-User Interfaces (Extra-UIs) have emerged as a modern evolution of the meta-UI, aiming to more explicitly empower users (and sometimes designers) to intervene in adaptive behaviors at runtime. The terminology was clarified to distinguish levels of control granularity in what Coutaz \etal called the ``(meta–extra–mega)-UI'' framework \cite{Demeure:2011}, in whic:
\begin{itemize}
  \item an \textbf{Extra-UI} provides mechanisms to observe and modify \emph{UI design decisions} at runtime by exposing the underlying UI models (for instance, allowing a user to redistribute UI components across available devices, or adjust interface parameters);
  \item a \textbf{Meta-UI} (in the updated sense) goes a level deeper, letting designers alter or extend the \emph{language or model} that defines the UI (\eg introducing new interaction modalities or rules into the UI’s specification);
  \item a \textbf{Mega-UI} is a hypothetical superset that permits observation and control of \emph{everything} in the interactive system-including the base UI, any Extra-UIs and Meta-UIs, and the relationships among them (\eg a Mega-UI could manage model-to-model transformations ~\cite{Sottet:2010} or the entire adaptation infrastructure itself) \cite{Vanderdonckt:2009}.
  \^item a \textbf{Supra-UI}
\end{itemize}

In practice, however, \textbf{most implementations that were historically called ``meta-UIs'' have in fact been instances of Extra-UIs}: additional interfaces giving end-users control over an adaptive system’s behavior, typically realized as graphical overlays, configuration panels, or control dashboards. The notion of Mega-UIs remains largely conceptual, representing an ultimate extension of the idea of user-control interfaces where the entire ecosystem of UIs-including Extra- and Meta-UIs-could be observed and manipulated.

While the Meta-UI concept has been revisited in various works, the Extra-UI notion has received comparatively little in-depth treatment: its definition, design space, and systematic design methods remain under-specified. This dissertation addresses that gap.

\paragraph{Extra-User Interfaces as focal concept.}
In line with this progression, Extra-User Interfaces serve as the focal point of our research. An Extra-UI can be seen as an interface layer that sits ``above'' or ``around'' the regular user interface of an application, with the dedicated purpose of making adaptation \textit{observable} and \textit{controllable} by users in real time. Rather than the system adapting silently and unilaterally, an Extra-UI offers tools for the user to~\cite{Melchior:2010}:
\begin{itemize}
  \item \textbf{Discover} what adaptive changes are possible or ongoing (e.g., viewing which UI elements have changed, which contextual rules fired, or which resources are available);
  \item \textbf{Remodel} or adjust the UI’s configuration (e.g., rearrange layout or swap a widget for an alternative);
  \item \textbf{Redistribute} parts of the interface across multiple screens or devices;
  \item \textbf{Parameterize} adaptive behaviors (e.g., tuning the sensitivity of a gesture recognizer or the threshold of an alert);
  \item \textbf{Extend} the interface with new functionality or content on the fly.
\end{itemize}

The five aforementioned capabilities emerge as core primitives of Extra-UIs and will be formally defined and positioned in a broader design space later in this thesis. By offering such services, Extra-UIs aim to strike a balance where the system can still perform automated adaptations (leveraging context-awareness and AI as appropriate), but the user is never a helpless bystander. Instead, the user gains oversight and veto power: they can monitor adaptation processes, intervene to correct or personalize outcomes, and thus remain in control of their interaction.

This restoration of user agency and insight is not merely a convenience; in safety-critical or mission-critical applications, it can be essential. In dynamic environments and high-stakes contexts-such as mid-air gestural control systems in interactive command centers, or investigative data visualization tools aiding police work-an Extra-UI can ensure that human operators have the final say and a clear understanding of interface changes that could impact their decisions. In summary, the context for this thesis is the challenge of adaptive user interfaces in ambient intelligent systems, and the motivation is to enhance those systems with a new class of meta-level interfaces-Extra-User Interfaces-that put users back in charge of UI adaptation. This sets the stage for a deeper investigation into what Extra-UIs are, how to design them, and how they improve the user experience of adaptive systems.

%\bigbreak

\section{Research Question}

Current AUIs too often treat the user as a passive subject of adaptation rather than an active controller of it. The core \textbf{research problem} addressed in this dissertation is therefore the lack of user control and transparency in automatic user interface adaptations. As adaptive and context-aware technologies proliferate, users frequently encounter situations where the software adjusts itself (its layout, content, or behavior) without their explicit consent or understanding. The origin of this problem lies in a design paradigm that prioritizes full automation of adaptation: the system monitors context and applies predefined adaptation rules or machine-learning-driven changes, while the user’s role is reduced to observing the outcome. Important UI changes may be hidden or insufficiently explained, and if the adaptation is inappropriate or undesired, the user has no straightforward means to alter it. This can lead to mismatches between the system’s assumptions and the user’s actual needs, undermining usability and trust. In short, adaptive systems have a tendency to violate the principle of predictability and controllability that is essential for user trust. Addressing this problem requires a new approach that reintroduces user agency into the adaptation loop.

This thesis tackles this problem through the lens of Extra-User Interfaces. There are two tightly coupled facets to this endeavour:
\begin{enumerate}
  \item \textbf{A general conceptual facet:} defining, characterizing, and structuring Extra-UIs as a concept in their own right, independently of a particular application domain;
  \item \textbf{An applied facet:} studying how Extra-UIs can be instantiated in adaptive and context-aware systems to restore transparency and user control over UI adaptation.
\end{enumerate}

The overarching research question guiding this work is:
\begin{quote}
\textit{How can we define, design, develop, and validate an Extra-User Interface that enables users to understand and control UI adaptations in context-aware interactive systems?}
\end{quote}

In other words, how can we empower end-users with an ``interface for controlling other interfaces'' so that adaptive behavior becomes user-steerable rather than opaque and system-driven? To answer this broad question systematically, we adopt the Goal–Question–Metric (GQM) approach \cite{Basili:1984}, which breaks down the primary goal into specific research questions and further into measurable objectives. Following the GQM model, our main goal (empowering users in adaptive UI contexts via Extra-UIs) is decomposed into three key research questions:

\begin{description}
\item[\textbf{Q1: What is an Extra-UI?}] What are the fundamental concepts, definitions, and scope of an Extra-User Interface? This question seeks to establish a formal definition of Extra-UIs and to delineate their design space, independently of a specific application. Answering Q1 involves identifying the core properties and primitives of Extra-UIs (e.g., the capabilities to rediscover, remodel, redistribute, parameterize, and extend a UI) and ensuring that this definition comprehensively covers the range of user-driven adaptation operations needed for interactive systems. The outcome of Q1 will be a clear conceptual framework that distinguishes Extra-UIs from related concepts (such as traditional Meta-UIs) and articulates the role Extra-UIs play in an interactive system.

\item[\textbf{Q2: How to design and develop an Extra-UI?}] What methods and tools are required to create an Extra-User Interface and integrate it into an existing adaptive system? This question addresses the methodological and engineering challenges of Extra-UIs. It encompasses designing the Extra-UI’s functionality and user experience (what services it provides and how users interact with them), as well as the architecture needed to support those services at runtime. Q2 entails developing a design method or process-likely model-based-to guide practitioners in implementing Extra-UIs. It also involves ensuring that the Extra-UI’s design aligns with a continuous adaptation loop (the feedback cycle through which the system senses context, adapts the UI, and incorporates user adjustments). Concretely, answering Q2 will produce a set of design principles, an architectural model, and possibly a notation or toolkit (for example, using the Software Process Engineering Metamodel, SPEM) that together enable systematic development of Extra-UIs within adaptive systems.

\item[\textbf{Q3: How to evaluate the usefulness and usability of an Extra-UI?}] As soon as an Extra-UI is built, how can we empirically assess its impact on user performance and experience? Q3 focuses on the evaluation framework for Extra-UIs. We must determine whether introducing an Extra-UI actually improves the situation for users of adaptive interfaces: Do users achieve better task outcomes or efficiency when they have an Extra-UI available? Do they feel more satisfied, in control, and confident about the system’s behavior? Answering Q3 involves identifying appropriate evaluation criteria and metrics-for instance, usability scores (such as System Usability Scale or User Experience Questionnaire results), task success and error rates, adaptation effectiveness measures, and subjective perceptions of transparency and controllability. It also involves designing user studies or experiments that compare adaptive systems \emph{with} versus \emph{without} Extra-UI support. The goal is to gather evidence on whether Extra-UIs deliver tangible benefits (and at what cost, if any, in terms of added complexity or interaction overhead).
\end{description}

These three research questions (Q1–Q3) form a coherent inquiry path: first establishing the concept of Extra-UI, then providing a method to realize it, and finally validating its value. They are directly aligned with the dissertation’s aim of tackling the lack of user control in adaptive UIs, and they will be revisited throughout the thesis. Each question is associated with specific goals and metrics (per the GQM approach) that guide our investigation and ensure that we can measure success. In summary, the research problem is rooted in the tension between automatic UI adaptation and user agency, and our questions seek to resolve this by conceptualizing a solution (Extra-UIs), operationalizing its design, and empirically measuring its effectiveness.

\section{Objectives and Contributions}

To address the research questions above, this Ph.D.\ work pursues several specific objectives and makes corresponding scientific contributions. The overarching goal is to establish the concept of the Extra-User Interface as a viable approach for user-controllable UI adaptation, and to demonstrate its feasibility and benefits through theoretical development and practical experimentation. The main contributions of this dissertation are outlined below.

\paragraph{A theoretical framework for Extra-User Interfaces.}
We develop a formal definition and conceptual framework for Extra-UIs, solidifying what an Extra-UI is and what it entails. This includes identifying the fundamental primitives or services that an Extra-UI can provide to end-users. In particular, the framework defines a set of five core Extra-UI capabilities: \textit{rediscover}, \textit{remodel}, \textit{redistribute}, \textit{parameterize}, and \textit{extend}. These primitives encapsulate the different ways an Extra-UI can intervene in an interface-from discovering the current state or available resources, to modifying the UI’s composition or distribution, to tuning parameters of adaptive behavior, to extending the interface’s functionality. By articulating these operations, the framework creates a common language to describe and compare Extra-UIs. It also positions Extra-UIs in relation to prior concepts (clarifying distinctions with Meta-UIs and Mega-UIs) and lays out a taxonomy or design space of Extra-UIs. This theoretical contribution builds on earlier work in user interface plasticity and Meta-UI design \cite{Demeure:2011}, and extends it by explicitly focusing on end-user empowerment and real-time control.

\paragraph{A model-based design method for integrating Extra-UIs into adaptive systems.}
We propose a structured methodology to guide designers and developers in implementing an Extra-UI as part of an adaptive user interface system. This contribution is methodological and is grounded in model-based user interface engineering principles \cite{Vanderdonckt:2008}. It consists of a process model and architectural blueprint for adding an Extra-UI layer to a system’s UI. Key elements include: (a) the use of behavioral and UI models to represent both the base adaptive UI and the Extra-UI, ensuring that the Extra-UI has access to the underlying UI’s state and adaptation logic; (b) integration of the Extra-UI into a continuous adaptation loop, meaning the system continuously senses context and user inputs, adapts the UI, and incorporates any adjustments made via the Extra-UI in a closed feedback cycle; and (c) a method-engineering approach using a standard notation (such as SPEM 2.0) to formally describe the design steps and roles involved in creating the Extra-UI. In practice, this design method provides guidelines on issues such as how to decide which adaptive aspects to expose to the user and in what form, how to maintain consistency between the Extra-UI and the primary UI, and how to handle user-initiated adaptation commands alongside automatic adaptations.

\paragraph{Implementation and evaluation of two Extra-UI prototypes.}
As proof-of-concept and to validate the proposed ideas, we have designed, implemented, and empirically evaluated two distinct prototypes of Extra-User Interfaces in real-world-inspired scenarios. The first prototype is a gestural Extra-UI for ambient environments: it builds upon a mid-air gesture-controlled smart space (using a Leap Motion sensor and the QUANTUMLEAP framework) and adds an Extra-UI that allows users to inspect and modify gesture-to-command mappings on the fly. The second prototype is an adaptive data visualization dashboard for investigative analysis (in the domain of criminal investigations), augmented with an Extra-UI panel that gives investigators control over the system’s adaptive visualization behavior. Both prototypes have been evaluated with target users through user studies, comparing usage of the adaptive system \textit{with} versus \textit{without} the Extra-UI. The results of these evaluations (detailed in later chapters) provide empirical evidence regarding the usefulness and usability of Extra-UIs.

In summary, the contributions of this thesis are: (1) a clarified concept and design space for Extra-User Interfaces, complete with defined primitives and taxonomy; (2) a novel model-based methodology for designing and integrating Extra-UIs into adaptive systems; and (3) two implemented Extra-UI systems with corresponding evaluations that evidence the benefits of re-introducing user control into UI adaptation.

\section{Working Hypotheses}
% To be detailed in a later iteration; this section will state the hypotheses derived from Q1--Q3.

\section{Methodology Overview}

Investigating Extra-User Interfaces requires a multi-layered research methodology that spans from conceptual foundations to practical validation. In this dissertation, we adopt a three-tier methodological approach, with each layer addressing one of the core aspects of the research (conceptualization, design, and evaluation). The approach can be summarized as follows:

\begin{enumerate}
\item \textbf{Conceptual layer – Definition and Taxonomy of Extra-UIs:} We begin at the theoretical level by formally defining what constitutes an Extra-User Interface and constructing a taxonomy of Extra-UIs. This involves a literature analysis of existing adaptive UI systems and Meta-UI examples, in order to extract common themes and capabilities that inform the Extra-UI definition. We identify the key services an Extra-UI should provide (the primitives introduced earlier) and specify how these services relate to underlying UI models and adaptation mechanisms. We also categorize Extra-UIs along meaningful dimensions-for example, distinguishing whether an Extra-UI is embedded within the primary UI or exists as a separate application, whether it manipulates digital content or physical devices, etc. The outcome of this layer is a clear ontological description of Extra-UIs and a structured design space that maps out possible variations of the concept. This conceptual groundwork answers Q1 (What is an Extra-UI?) by delivering a rigorous definition and classification, which then guides all subsequent work.

\item \textbf{Methodological layer – Model-Based Design and Integration Process:} Building on the concept definition, the next layer develops a methodology for designing and integrating Extra-UIs into adaptive systems. We utilize a model-based engineering approach, employing modeling techniques to represent both the interactive system and the Extra-UI. In particular, we use the SPEM (Software Process Engineering Metamodel) framework to model the development process of an Extra-UI, and we incorporate the notion of a continuous adaptation loop (a cyclical process of context sensing, adaptation decision, UI update, and user feedback) into the system architecture. This layer produces a model-based design method (answering Q2: How to design/develop an Extra-UI?) that serves as a blueprint others can follow.

\item \textbf{Implementation \& Evaluation layer – Prototyping and Empirical Studies:} The final layer is highly practical: we implement concrete Extra-UI prototypes and conduct user evaluations to test our hypotheses. We instantiate the conceptual framework and design method in two case studies (the gestural interaction scenario and the investigative visualization scenario). We then perform empirical evaluations by inviting representative users to use these systems in controlled settings, gathering both quantitative data (e.g., task completion times, error rates) and qualitative feedback (e.g., SUS/UEQ scores, interviews about perceived transparency and control). Comparative study designs isolate the effect of the Extra-UI by contrasting conditions with and without Extra-UI support. This layer directly addresses Q3 (How to evaluate an Extra-UI?) and feeds back into refining our framework and method.
\end{enumerate}

Through this three-layer approach, the methodology covers the full spectrum of the research: from abstract theory to concrete design prescriptions to validated outcomes. It ensures that our work on Extra-UIs is both conceptually sound and empirically substantiated.

\section{List of Contributions}
% This section will later provide a compact, bullet-point summary of the contributions detailed above (framework, method, prototypes and evaluations).

\section{Manuscript Overview}

The remainder of this manuscript is organized as follows:

\begin{itemize}
  \item \textbf{Chapter 2 – Related Work:} introduces the state of the art on adaptive user interfaces, UI plasticity, Meta-UIs and related concepts, with a particular focus on how prior work has (or has not) addressed user control and transparency in adaptive systems.
  \item \textbf{Chapter 3 – Contextual Adaptation and Extra-UI Design Space:} presents the theoretical background on contextual adaptation and synthesizes existing work (including the encyclopedia chapter with Calvary) into a structured set of concepts that prepare the ground for Extra-UIs.
  \item \textbf{Chapter 4 – Concept and Design Space of Extra-User Interfaces:} defines Extra-UIs formally, introduces their core primitives, and elaborates a design space and taxonomy that distinguish Extra-UIs from Meta-UIs and other related notions.
  \item \textbf{Chapter 5 – Model-Based Methodology for Extra-UI Development:} details the proposed model-based process and architectural patterns for integrating Extra-UIs into adaptive systems, using SPEM and related modeling tools.
  \item \textbf{Chapter 6 – Prototypical Implementations and Evaluations:} describes the two Extra-UI prototypes (gestural Extra-UI and investigative dashboard Extra-UI), the design decisions behind them, and the empirical studies conducted to evaluate their usefulness and usability.
  \item \textbf{Chapter 7 – Discussion and Conclusion:} synthesizes the results, discusses limitations and generalizability, and outlines perspectives for future research on Extra-User Interfaces and user-controllable adaptation.
\end{itemize}
